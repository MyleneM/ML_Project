{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 20201221_Statistics_Advanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "#import nltk.tokenize\n",
    "#import nltk.tag\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('averaged_perceptron_tagger')\n",
    "#from nltk.corpus import stopwords\n",
    "import statistics as stat\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    }
   ],
   "source": [
    "#nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def int_punct(df): \n",
    "    res_vi = []\n",
    "    res_pv = []\n",
    "    res_ti = []\n",
    "    for k in range(len(df.axes[0])): \n",
    "        a = df['Review'][k]\n",
    "        v = 0\n",
    "        p = 0\n",
    "        t = 0\n",
    "        if pd.isna(a)==False: \n",
    "            for c in a: \n",
    "                if c==',': \n",
    "                    v = v+1\n",
    "                if c==';':\n",
    "                    p = p+1\n",
    "                if c==' - ': # espace pour ne pas prendre en compte les mots composes \n",
    "                    t = t+1\n",
    "        s = v+p+t\n",
    "        if s==0: \n",
    "            res_vi.append(None)\n",
    "            res_pv.append(None)\n",
    "            res_ti.append(None)\n",
    "        else:     \n",
    "            res_vi.append(v/s*100)\n",
    "            res_pv.append(p/s*100)\n",
    "            res_ti.append(t/s*100)\n",
    "    res = pd.DataFrame({'ID':range(len(df.axes[0])),\n",
    "                        'Virgules_pct':res_vi,\n",
    "                        'Point_virgules_pct':res_pv,\n",
    "                        'Tirets_pct':res_ti})\n",
    "    return(res)    \n",
    "\n",
    "# Calcul des % pour la ponctuation externe aux phrases: \n",
    "def ext_punct(df): \n",
    "    res_dec = []\n",
    "    res_int = []\n",
    "    res_exc = []\n",
    "    for k in range(len(df.axes[0])): \n",
    "        a = df['Review'][k]\n",
    "        d = 0\n",
    "        i = 0\n",
    "        e = 0\n",
    "        if pd.isna(a)==False: \n",
    "            for c in a: \n",
    "                if c=='.': \n",
    "                    d = d+1\n",
    "                if c=='?':\n",
    "                    i = i+1\n",
    "                if c=='!': \n",
    "                    e = e+1\n",
    "        s = d+i+e\n",
    "        if s==0: \n",
    "            res_dec.append(None)\n",
    "            res_int.append(None)\n",
    "            res_exc.append(None)\n",
    "        else:     \n",
    "            res_dec.append(d/s*100)\n",
    "            res_int.append(i/s*100)\n",
    "            res_exc.append(e/s*100)\n",
    "    res = pd.DataFrame({'ID':range(len(df.axes[0])),\n",
    "                        'Declaratives_pct':res_dec,\n",
    "                        'Interrogatives_pct':res_int,\n",
    "                        'Exclamatives_pct':res_exc})\n",
    "    return(res)\n",
    "    \n",
    "# Calcul des % des differents types de mots dans chaque critique: \n",
    "def type_mots(df):\n",
    "    # Les types de mots recherches: \n",
    "    adv = ['RB','RBR','RBS']\n",
    "    nn = ['NN','NNS','NNP','NNPS']\n",
    "    vb = ['VB','VBD','VBG','VBN','VBP','VBZ']\n",
    "    adj = ['JJ','JJR']\n",
    "    ads = ['JJS']\n",
    "    # Listes vides pour stocker les resultats\n",
    "    res_mots = []\n",
    "    res_adv = []\n",
    "    res_nn = []\n",
    "    res_vb = []\n",
    "    res_adj = []\n",
    "    res_ads = []\n",
    "    for k in range(len(df.axes[0])):\n",
    "    #for k in range(10):\n",
    "        t = df['Review'][k]\n",
    "        # Set counters to 0: \n",
    "        ca = 0\n",
    "        cn = 0\n",
    "        cv = 0\n",
    "        cj = 0\n",
    "        cs = 0\n",
    "        if pd.isna(t)==False: \n",
    "            t_tok = nltk.word_tokenize(t)\n",
    "            res_mots.append(len(t_tok))\n",
    "            if len(t_tok)==0: # ie si pas de texte de critique\n",
    "                res_adv.append(None)\n",
    "                res_nn.append(None)\n",
    "                res_vb.append(None)\n",
    "                res_adj.append(None)\n",
    "                res_ads.append(None)\n",
    "            else: \n",
    "                t_tag = nltk.pos_tag(t_tok)\n",
    "                for x in t_tag: \n",
    "                    if x[1] in adv: \n",
    "                        ca = ca+1\n",
    "                    if x[1] in nn: \n",
    "                        cn = cn+1\n",
    "                    if x[1] in vb: \n",
    "                        cv = cv+1\n",
    "                    if x[1] in adj: \n",
    "                        cj = cj+1\n",
    "                    if x[1] in ads: \n",
    "                        cs = cs+1\n",
    "                res_adv.append(ca/len(t_tok))\n",
    "                res_nn.append(cn/len(t_tok))\n",
    "                res_vb.append(cv/len(t_tok))\n",
    "                res_adj.append(cj/len(t_tok))\n",
    "                res_ads.append(cs/len(t_tok))\n",
    "        else: \n",
    "            res_mots.append(None)\n",
    "            res_adv.append(None)\n",
    "            res_nn.append(None)\n",
    "            res_vb.append(None)\n",
    "            res_adj.append(None)\n",
    "            res_ads.append(None)\n",
    "    res = pd.DataFrame({'ID':range(len(df.axes[0])),\n",
    "                        'Nb_mots':res_mots,\n",
    "                        'Adverbes':res_adv,\n",
    "                        'Noms':res_nn,\n",
    "                        'Verbes':res_vb,\n",
    "                        'Adjectifs':res_adj,\n",
    "                        'Superlatifs':res_ads})\n",
    "    return res\n",
    "\n",
    "# 15 mots les plus frequents, selon le type de mots: \n",
    "# ty = type de mot dont on souhaite obtenir le top 15\n",
    "# Valeurs possibles: 'nom', 'adj', 'adv', 'sup', 'vb'\n",
    "def top_15(df,ty): \n",
    "    # Def. des tags a rechercher: \n",
    "    if ty=='nom': tg = ['NN','NNS','NNP','NNPS']\n",
    "    if ty=='adj': tg = ['JJ','JJR']\n",
    "    if ty=='sup': tg = ['JJS']\n",
    "    if ty=='adv': tg = ['RB','RBR','RBS']\n",
    "    if ty=='vb': tg = ['VB','VBD','VBG','VBN','VBP','VBZ']\n",
    "    l = {} # dictionnaire qui prendra en cle les mots et en valeur leur nb d'occurrences \n",
    "    for k in range(len(df.axes[0])):\n",
    "        t = df['Review'][k]\n",
    "        if pd.isna(t)==False: \n",
    "            t = t.lower()\n",
    "            t_tok = nltk.word_tokenize(t)\n",
    "            if len(t_tok)!=0:\n",
    "                t_tag = nltk.pos_tag(t_tok)\n",
    "                for x in t_tag: \n",
    "                    if x[1] in tg: \n",
    "                        if x[0] in l: \n",
    "                            l[x[0]] = l[x[0]]+1\n",
    "                        else: \n",
    "                            l[x[0]]=1\n",
    "    res = sorted(l.items(), key=lambda x: x[1]) # liste de couples\n",
    "    # Retirer les 'parasites': \n",
    "    pb = ['\"','“','’','—','”','t','n','‘','s']\n",
    "    res = [x for x in res if x[0] not in pb]        \n",
    "    res15 = res[len(res)-16:len(res)-1]\n",
    "    return res15\n",
    "\n",
    "# % verbes conjugues au passe / present / futur: \n",
    "def tps_vb(df): \n",
    "    pr = ['VBP','VBZ','VBG']\n",
    "    ps = ['VBD','VBN']\n",
    "    # VB: cas particulier (present / futur)\n",
    "    res_pr = []\n",
    "    res_ps = []\n",
    "    res_fu = []\n",
    "    for k in range(len(df.axes[0])):\n",
    "        t = df['Review'][k]\n",
    "        cpr = 0\n",
    "        cps = 0\n",
    "        cfu = 0\n",
    "        if pd.isna(t)==False: \n",
    "            t_tok = nltk.word_tokenize(t)\n",
    "            if len(t_tok)==0: # ie si pas de texte de critique\n",
    "                res_pr.append(None)\n",
    "                res_ps.append(None)\n",
    "                res_fu.append(None)\n",
    "            else: \n",
    "                t_tag = nltk.pos_tag(t_tok)\n",
    "                for j in range(len(t_tag)): \n",
    "                    if t_tag[j][1] in pr: \n",
    "                        cpr = cpr+1\n",
    "                    if t_tag[j][1] in ps: \n",
    "                        cps = cps+1\n",
    "                    if t_tag[j][1]=='VB': \n",
    "                        if j!=0: \n",
    "                            if t_tag[j-1][0]=='will': \n",
    "                                cfu = cfu+1\n",
    "                        else: \n",
    "                            cpr = cpr+1\n",
    "                res_pr.append(cpr)\n",
    "                res_ps.append(cps)\n",
    "                res_fu.append(cfu)\n",
    "        else: \n",
    "            res_pr.append(None)\n",
    "            res_ps.append(None)\n",
    "            res_fu.append(None)\n",
    "    res = pd.DataFrame({'ID':range(len(df.axes[0])),\n",
    "                        'Passe':res_ps,\n",
    "                        'Present':res_pr,\n",
    "                        'Futur':res_fu})\n",
    "    return res\n",
    "\n",
    "# Pronoms personnels utilises:\n",
    "def pronoms_perso(df): \n",
    "    # Pronoms que l'on veut compter: \n",
    "    i = ['I','me','my','mine']\n",
    "    you = ['you','yours','your']\n",
    "    he = ['he','she','him','his','her','hers']\n",
    "    we = ['we','us','our','ours']\n",
    "    they = ['they','them','their','theirs']\n",
    "    res_i = [] \n",
    "    res_you = [] \n",
    "    res_he = [] \n",
    "    res_we = [] \n",
    "    res_they = [] \n",
    "    for k in range(len(df.axes[0])):\n",
    "        t = df['Review'][k]\n",
    "        ci = 0\n",
    "        cy = 0\n",
    "        ch = 0\n",
    "        cw = 0\n",
    "        ct = 0\n",
    "        if pd.isna(t)==False: \n",
    "            t_tok = nltk.word_tokenize(t)\n",
    "            if len(t_tok)==0: # ie si pas de texte de critique\n",
    "                res_i.append(None)\n",
    "                res_you.append(None)\n",
    "                res_he.append(None)\n",
    "                res_we.append(None)\n",
    "                res_they.append(None)\n",
    "            else: \n",
    "                t_tag = nltk.pos_tag(t_tok)\n",
    "                for x in t_tag: \n",
    "                    if x[1]=='PRP' or x[1]=='PRP$':\n",
    "                        if x[0] in i: \n",
    "                            ci = ci+1\n",
    "                        if x[0] in you: \n",
    "                            cy = cy+1\n",
    "                        if x[0] in he: \n",
    "                            ch = ch+1\n",
    "                        if x[0] in we: \n",
    "                            cw = cw+1\n",
    "                        if x[0] in they: \n",
    "                            ct = ct+1\n",
    "                res_i.append(ci)\n",
    "                res_you.append(cy)\n",
    "                res_he.append(ch)\n",
    "                res_we.append(cw)\n",
    "                res_they.append(ct)\n",
    "        else: \n",
    "            res_i.append(None)\n",
    "            res_you.append(None)\n",
    "            res_he.append(None)\n",
    "            res_we.append(None)\n",
    "            res_they.append(None)\n",
    "    res = pd.DataFrame({'ID':range(len(df.axes[0])),\n",
    "                        '1e_pers_s':res_i,\n",
    "                        '2e_pers':res_you,\n",
    "                        '3e_pers_s':res_he,\n",
    "                        '1e_pers_p':res_we,\n",
    "                        '3e_pers_p':res_they})\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "C1 = pd.read_excel('20210508_corpus_I_v3.5.xlsx')\n",
    "C2 = pd.read_excel('20210411_final_corpusII.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "C1 = pd.read_csv('../Corpus I/20201221_Corpus_I_v2.csv')\n",
    "C2 = pd.read_csv('../Corpus II/20201221_Corpus_II_v1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Newspaper</th>\n",
       "      <th>Date</th>\n",
       "      <th>Reviewer</th>\n",
       "      <th>Title</th>\n",
       "      <th>Theatre</th>\n",
       "      <th>Review</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long</th>\n",
       "      <th>Spectator_Cat</th>\n",
       "      <th>...</th>\n",
       "      <th>Word_Average_End_1</th>\n",
       "      <th>Word_Average_Start_2</th>\n",
       "      <th>Word_Average_End_2</th>\n",
       "      <th>Word_Average_Start_3</th>\n",
       "      <th>Word_Average_End_3</th>\n",
       "      <th>First_Name_Reviewer</th>\n",
       "      <th>Gender_First_Name_Reviewer</th>\n",
       "      <th>Review_Clean</th>\n",
       "      <th>Cluster_LDA</th>\n",
       "      <th>Cluster_LDA_Calculation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3770</td>\n",
       "      <td>SUNDAY</td>\n",
       "      <td>26/2/2012</td>\n",
       "      <td>Claudia Pritchard</td>\n",
       "      <td>THE BOMB: A PARTIAL HISTORY Two-part collectio...</td>\n",
       "      <td>T ricycle\\t</td>\n",
       "      <td>INDEPENDENT on Weeping, crying, moaning, sighi...</td>\n",
       "      <td>51.543323</td>\n",
       "      <td>-0.200005</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4.56</td>\n",
       "      <td>n.a</td>\n",
       "      <td>5.1</td>\n",
       "      <td>n.a</td>\n",
       "      <td>4.7</td>\n",
       "      <td>Claudia</td>\n",
       "      <td>female</td>\n",
       "      <td>['independent', 'weeping', 'cry', 'moaning', '...</td>\n",
       "      <td>cluster5</td>\n",
       "      <td>(4, '0.008*\"play\" + 0.007*\"production\" + 0.004...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12678</td>\n",
       "      <td>12.5.13 SUNDAY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kate Bassett</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>﻿﻿INDEPENDENT on We used to have angels on our...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.25</td>\n",
       "      <td>4.3</td>\n",
       "      <td>6.05</td>\n",
       "      <td>4.48</td>\n",
       "      <td>5.67</td>\n",
       "      <td>Kate</td>\n",
       "      <td>female</td>\n",
       "      <td>['\\ufeff\\ufeffindependent', 'used', 'angel', '...</td>\n",
       "      <td>cluster5</td>\n",
       "      <td>(4, '0.008*\"play\" + 0.007*\"production\" + 0.004...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10161</td>\n",
       "      <td>9.1.11 SUNDAY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kate Bassett</td>\n",
       "      <td>IVONA, PRINCESS OF BURGUNDIA Revival of play</td>\n",
       "      <td>Network\\t</td>\n",
       "      <td>﻿INDEPENDENT on Veer to the right, past the in...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.8</td>\n",
       "      <td>5.32</td>\n",
       "      <td>5.62</td>\n",
       "      <td>5.32</td>\n",
       "      <td>5.89</td>\n",
       "      <td>Kate</td>\n",
       "      <td>female</td>\n",
       "      <td>['\\ufeffindependent', 'veer', 'right', 'past',...</td>\n",
       "      <td>cluster5</td>\n",
       "      <td>(4, '0.008*\"play\" + 0.007*\"production\" + 0.004...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 69 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index        Newspaper       Date           Reviewer  \\\n",
       "0   3770          SUNDAY   26/2/2012  Claudia Pritchard   \n",
       "1  12678  12.5.13 SUNDAY         NaN      Kate Bassett    \n",
       "2  10161    9.1.11 SUNDAY        NaN       Kate Bassett   \n",
       "\n",
       "                                               Title      Theatre  \\\n",
       "0  THE BOMB: A PARTIAL HISTORY Two-part collectio...  T ricycle\\t   \n",
       "1                                                NaN          NaN   \n",
       "2       IVONA, PRINCESS OF BURGUNDIA Revival of play    Network\\t   \n",
       "\n",
       "                                              Review        Lat      Long  \\\n",
       "0  INDEPENDENT on Weeping, crying, moaning, sighi...  51.543323 -0.200005   \n",
       "1  ﻿﻿INDEPENDENT on We used to have angels on our...        NaN       NaN   \n",
       "2  ﻿INDEPENDENT on Veer to the right, past the in...        NaN       NaN   \n",
       "\n",
       "   Spectator_Cat  ...  Word_Average_End_1  Word_Average_Start_2  \\\n",
       "0              1  ...                4.56                   n.a   \n",
       "1              0  ...                7.25                   4.3   \n",
       "2              0  ...                 3.8                  5.32   \n",
       "\n",
       "   Word_Average_End_2  Word_Average_Start_3  Word_Average_End_3  \\\n",
       "0                 5.1                   n.a                 4.7   \n",
       "1                6.05                  4.48                5.67   \n",
       "2                5.62                  5.32                5.89   \n",
       "\n",
       "   First_Name_Reviewer  Gender_First_Name_Reviewer  \\\n",
       "0              Claudia                      female   \n",
       "1                 Kate                      female   \n",
       "2                 Kate                      female   \n",
       "\n",
       "                                        Review_Clean  Cluster_LDA  \\\n",
       "0  ['independent', 'weeping', 'cry', 'moaning', '...     cluster5   \n",
       "1  ['\\ufeff\\ufeffindependent', 'used', 'angel', '...     cluster5   \n",
       "2  ['\\ufeffindependent', 'veer', 'right', 'past',...     cluster5   \n",
       "\n",
       "                             Cluster_LDA_Calculation  \n",
       "0  (4, '0.008*\"play\" + 0.007*\"production\" + 0.004...  \n",
       "1  (4, '0.008*\"play\" + 0.007*\"production\" + 0.004...  \n",
       "2  (4, '0.008*\"play\" + 0.007*\"production\" + 0.004...  \n",
       "\n",
       "[3 rows x 69 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C1.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "########################################\n",
    "# 1. Syntaxe - Ponctuation interne     #\n",
    "########################################\n",
    "# % de virgules / point-virgules / tirets dans la critique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "C1_PI = int_punct(C1)\n",
    "C2_PI = int_punct(C2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "C1_PI.to_csv('20201221_C1_PI.csv',na_rep='NA')\n",
    "C2_PI.to_csv('20201221_C2_PI.csv',na_rep='NA')\n",
    "\n",
    "C1_PI.to_excel('20201221_C1_PI.xlsx',na_rep='NA')\n",
    "C2_PI.to_excel('20201221_C2_PI.xlsx',na_rep='NA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "########################################\n",
    "# 2. Syntaxe - Ponctuation externe     #\n",
    "########################################\n",
    "# % phrases declaratives / interrogatives / exclamatives dans la critique\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "C1_PE = ext_punct(C1)\n",
    "C2_PE = ext_punct(C2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "C1_PE.to_csv('20201221_C1_PE.csv',na_rep='NA')\n",
    "C2_PE.to_csv('20201221_C2_PE.csv',na_rep='NA')\n",
    "\n",
    "C1_PE.to_excel('20201221_C1_PE.xlsx',na_rep='NA')\n",
    "C2_PE.to_excel('20201221_C2_PE.xlsx',na_rep='NA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "########################################\n",
    "# 3. Lexique - Types de mots           #\n",
    "########################################\n",
    "# % adverbes, noms, verbes, adjectifs qualificatifs, superlatifs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "C1_type = type_mots(C1)\n",
    "C2_type = type_mots(C2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "C1_type.to_csv('20201221_C1_typemots.csv',na_rep='NA')\n",
    "C2_type.to_csv('20201221_C2_typemots.csv',na_rep='NA')\n",
    "C1_type.to_excel('20201221_C1_typemots.xlsx',na_rep='NA')\n",
    "C2_type.to_excel('20201221_C2_typemots.xlsx',na_rep='NA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "########################################\n",
    "# 4. Lexique - Mots les plus frequents #\n",
    "########################################\n",
    "# 15 adverbes / noms / verbes / adjectifs / superlatifs les + frequents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "C1_adv_top15 = top_15(C1,'adv')\n",
    "# ['now','still','rather','never','then','well','here','as','only','just',\n",
    "# 'even','too','also','more','so']\n",
    "C1_nom_top15 =  top_15(C1,'nom')\n",
    "#['London','years','theatre','audience','characters','way','story','time',\n",
    "# 'performance','man','life','stage','show','production','play']\n",
    "C1_vb_top15 =  top_15(C1,'vb')\n",
    "#['set','see','make','being','seems','had','do','does','makes','been',\n",
    "# 'was','have','be','has','are']\n",
    "C1_adj_top15 =  top_15(C1,'adj')\n",
    "# ['real','many','last','such','old','little','great','good','much','first',\n",
    "# 'young','other','own','more','new']\n",
    "C1_sup_top15 =  top_15(C1,'sup')\n",
    "#['oldest','forest','youngest','earnest','strongest','funniest','worst','honest',\n",
    "# 'finest','west','biggest','greatest','latest','least','most']\n",
    "\n",
    "C2_adv_top15 = top_15(C2,'adv')\n",
    "C2_nom_top15 = top_15(C2,'nom')\n",
    "C2_vb_top15 = top_15(C2,'vb')\n",
    "C2_adj_top15 = top_15(C2,'adj')\n",
    "C2_sup_top15 = top_15(C2,'sup')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_C1_adv_top15 = pd.DataFrame(C1_adv_top15, columns=['Top 15 Adv C1', 'Top 15 Adv Frequency C1'])\n",
    "df_C1_nom_top15 = pd.DataFrame(C1_nom_top15, columns=['Top 15 Nom C1', 'Top 15 Nom Frequency C1'])\n",
    "df_C1_vb_top15 = pd.DataFrame(C1_vb_top15, columns=['Top 15 Vb C1', 'Top 15 Vb Frequency C1'])\n",
    "df_C1_adj_top15 = pd.DataFrame(C1_adj_top15, columns=['Top 15 Adj C1', 'Top 15 Adj Frequency C1'])\n",
    "df_C1_sup_top15 = pd.DataFrame(C1_sup_top15, columns=['Top 15 Sup C1', 'Top 15 Sup Frequency C1'])\n",
    "df_C2_adv_top15 = pd.DataFrame(C2_adv_top15, columns=['Top 15 Adv C2', 'Top 15 Adv Frequency C2'])\n",
    "df_C2_nom_top15 = pd.DataFrame(C2_nom_top15, columns=['Top 15 Nom C2', 'Top 15 Nom Frequency C2'])\n",
    "df_C2_vb_top15 = pd.DataFrame(C2_vb_top15, columns=['Top 15 Vb C2', 'Top 15 Vb Frequency C2'])\n",
    "df_C2_adj_top15 = pd.DataFrame(C2_adj_top15, columns=['Top 15 Adj C2', 'Top 15 Adj Frequency C2'])\n",
    "df_C2_sup_top15 = pd.DataFrame(C2_sup_top15, columns=['Top 15 Sup C2', 'Top 15 Sup Frequency C2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top15 = pd.DataFrame({'Top 15 Adv C1':df_C1_adv_top15['Top 15 Adv C1'],\n",
    "                        'Top 15 Adv Frequency C1':df_C1_adv_top15['Top 15 Adv Frequency C1'],\n",
    "                        'Top 15 Nom C1':df_C1_nom_top15['Top 15 Nom C1'],\n",
    "                        'Top 15 Nom Frequency C1':df_C1_nom_top15['Top 15 Nom Frequency C1'],\n",
    "                        'Top 15 Vb C1':df_C1_vb_top15['Top 15 Vb C1'],\n",
    "                        'Top 15 Vb Frequency C1':df_C1_vb_top15['Top 15 Vb Frequency C1'],\n",
    "                        'Top 15 Adj C1':df_C1_adj_top15['Top 15 Adj C1'],\n",
    "                        'Top 15 Adj Frequency C1':df_C1_adj_top15['Top 15 Adj Frequency C1'],\n",
    "                        'Top 15 Sup C1':df_C1_sup_top15['Top 15 Sup C1'],\n",
    "                        'Top 15 Sup Frequency C1':df_C1_sup_top15['Top 15 Sup Frequency C1'],\n",
    "                        'Top 15 Adv C2':df_C2_adv_top15['Top 15 Adv C2'],\n",
    "                        'Top 15 Adv Frequency C2':df_C2_adv_top15['Top 15 Adv Frequency C2'],\n",
    "                        'Top 15 Nom C2':df_C2_nom_top15['Top 15 Nom C2'],\n",
    "                        'Top 15 Nom Frequency C2':df_C2_nom_top15['Top 15 Nom Frequency C2'],\n",
    "                        'Top 15 Vb C2':df_C2_vb_top15['Top 15 Vb C2'],\n",
    "                        'Top 15 Vb Frequency C2':df_C2_vb_top15['Top 15 Vb Frequency C2'],\n",
    "                        'Top 15 Adj C2':df_C2_adj_top15['Top 15 Adj C2'],\n",
    "                        'Top 15 Adj Frequency C2':df_C2_adj_top15['Top 15 Adj Frequency C2'],\n",
    "                        'Top 15 Sup C2':df_C2_sup_top15['Top 15 Sup C2'],\n",
    "                        'Top 15 Sup Frequency C2':df_C2_sup_top15['Top 15 Sup Frequency C2']\n",
    "                        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Top 15 Adv C1</th>\n",
       "      <th>Top 15 Adv Frequency C1</th>\n",
       "      <th>Top 15 Nom C1</th>\n",
       "      <th>Top 15 Nom Frequency C1</th>\n",
       "      <th>Top 15 Vb C1</th>\n",
       "      <th>Top 15 Vb Frequency C1</th>\n",
       "      <th>Top 15 Adj C1</th>\n",
       "      <th>Top 15 Adj Frequency C1</th>\n",
       "      <th>Top 15 Sup C1</th>\n",
       "      <th>Top 15 Sup Frequency C1</th>\n",
       "      <th>Top 15 Adv C2</th>\n",
       "      <th>Top 15 Adv Frequency C2</th>\n",
       "      <th>Top 15 Nom C2</th>\n",
       "      <th>Top 15 Nom Frequency C2</th>\n",
       "      <th>Top 15 Vb C2</th>\n",
       "      <th>Top 15 Vb Frequency C2</th>\n",
       "      <th>Top 15 Adj C2</th>\n",
       "      <th>Top 15 Adj Frequency C2</th>\n",
       "      <th>Top 15 Sup C2</th>\n",
       "      <th>Top 15 Sup Frequency C2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>very</td>\n",
       "      <td>6600</td>\n",
       "      <td>cast</td>\n",
       "      <td>7019</td>\n",
       "      <td>get</td>\n",
       "      <td>6041</td>\n",
       "      <td>last</td>\n",
       "      <td>4786</td>\n",
       "      <td>closest</td>\n",
       "      <td>121</td>\n",
       "      <td>never</td>\n",
       "      <td>8179</td>\n",
       "      <td>people</td>\n",
       "      <td>10636</td>\n",
       "      <td>make</td>\n",
       "      <td>9348</td>\n",
       "      <td>same</td>\n",
       "      <td>5873</td>\n",
       "      <td>closest</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>never</td>\n",
       "      <td>6718</td>\n",
       "      <td>end</td>\n",
       "      <td>7232</td>\n",
       "      <td>make</td>\n",
       "      <td>6526</td>\n",
       "      <td>many</td>\n",
       "      <td>4901</td>\n",
       "      <td>oldest</td>\n",
       "      <td>130</td>\n",
       "      <td>then</td>\n",
       "      <td>8746</td>\n",
       "      <td>cast</td>\n",
       "      <td>11877</td>\n",
       "      <td>get</td>\n",
       "      <td>9977</td>\n",
       "      <td>musical</td>\n",
       "      <td>6419</td>\n",
       "      <td>oldest</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>then</td>\n",
       "      <td>7320</td>\n",
       "      <td>world</td>\n",
       "      <td>7301</td>\n",
       "      <td>had</td>\n",
       "      <td>6659</td>\n",
       "      <td>musical</td>\n",
       "      <td>5442</td>\n",
       "      <td>strongest</td>\n",
       "      <td>179</td>\n",
       "      <td>n't</td>\n",
       "      <td>8795</td>\n",
       "      <td>performance</td>\n",
       "      <td>11986</td>\n",
       "      <td>does</td>\n",
       "      <td>10142</td>\n",
       "      <td>such</td>\n",
       "      <td>6476</td>\n",
       "      <td>earnest</td>\n",
       "      <td>212</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Top 15 Adv C1  Top 15 Adv Frequency C1 Top 15 Nom C1  \\\n",
       "0          very                     6600          cast   \n",
       "1         never                     6718           end   \n",
       "2          then                     7320         world   \n",
       "\n",
       "   Top 15 Nom Frequency C1 Top 15 Vb C1  Top 15 Vb Frequency C1 Top 15 Adj C1  \\\n",
       "0                     7019          get                    6041          last   \n",
       "1                     7232         make                    6526          many   \n",
       "2                     7301          had                    6659       musical   \n",
       "\n",
       "   Top 15 Adj Frequency C1 Top 15 Sup C1  Top 15 Sup Frequency C1  \\\n",
       "0                     4786       closest                      121   \n",
       "1                     4901        oldest                      130   \n",
       "2                     5442     strongest                      179   \n",
       "\n",
       "  Top 15 Adv C2  Top 15 Adv Frequency C2 Top 15 Nom C2  \\\n",
       "0         never                     8179        people   \n",
       "1          then                     8746          cast   \n",
       "2           n't                     8795   performance   \n",
       "\n",
       "   Top 15 Nom Frequency C2 Top 15 Vb C2  Top 15 Vb Frequency C2 Top 15 Adj C2  \\\n",
       "0                    10636         make                    9348          same   \n",
       "1                    11877          get                    9977       musical   \n",
       "2                    11986         does                   10142          such   \n",
       "\n",
       "   Top 15 Adj Frequency C2 Top 15 Sup C2  Top 15 Sup Frequency C2  \n",
       "0                     5873       closest                      192  \n",
       "1                     6419        oldest                      200  \n",
       "2                     6476       earnest                      212  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_top15.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top15.to_csv('20201221_top_15.csv',na_rep='NA')\n",
    "df_top15.to_excel('20201221_top_15.xlsx',na_rep='NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "########################################\n",
    "# 5. Syntaxe - Temps des verbes        #\n",
    "########################################\n",
    "# % verbes passe / present / futur\n",
    "# present = VBP, VBZ, VBG, VB sans 'will' devant\n",
    "# passe = VBD, VBN\n",
    "# futur = VB avec 'will' devant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "C1_vb = tps_vb(C1)\n",
    "C2_vb = tps_vb(C2)\n",
    "\n",
    "\n",
    "# Stockage: \n",
    "C1_vb.to_csv('20201221_C1_vb.csv',na_rep='NA')\n",
    "C2_vb.to_csv('20201221_C2_vb.csv',na_rep='NA')\n",
    "\n",
    "\n",
    "C1_vb.to_excel('20201221_C1_vb.xlsx',na_rep='NA')\n",
    "C2_vb.to_excel('20201221_C2_vb.xlsx',na_rep='NA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "########################################\n",
    "# 6. Lexique - Emotions                #\n",
    "########################################\n",
    "# Quels pronoms personnels sont utilises ?\n",
    "# PRP = personal pronouns ; PRP$ = possessive personal pronouns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "C1_pp = pronoms_perso(C1)\n",
    "C2_pp = pronoms_perso(C2)\n",
    "\n",
    "# Stockage: \n",
    "C1_pp.to_csv('20201221_C1_pp.csv',na_rep='NA')\n",
    "C2_pp.to_csv('20201221_C2_pp.csv',na_rep='NA')\n",
    "C1_pp.to_csv('20201221_C1_pp.xlsx',na_rep='NA')\n",
    "C2_pp.to_csv('20201221_C2_pp.xlsx',na_rep='NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
