{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pS9lDblHONBx"
   },
   "source": [
    "# Sentiment Analysis\n",
    "![alt text](https://ai2-s2-public.s3.amazonaws.com/figures/2017-08-08/0cc39c70021d21fc0d2fd7a986ccd242bef86c29/6-Figure1-1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3E3QOWoqaJAn"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set(rc={'figure.figsize':(30,1)})\n",
    "\n",
    "def visualise_sentiments(data):\n",
    "  sns.heatmap(pd.DataFrame(data).set_index(\"Sentence\").T,center=0, annot=True, cmap = \"PiYG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QBpYqUI0SNiI"
   },
   "outputs": [],
   "source": [
    "sentence = \"i really like you but you can be so dumb some times\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PnFIqyY7OIuu"
   },
   "source": [
    "## NLTK Vader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0PWxpQSAO6x2"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "sid = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ESebaEaTcD6l"
   },
   "outputs": [],
   "source": [
    "sid.polarity_scores(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nfsz-MWVWHTH"
   },
   "outputs": [],
   "source": [
    "visualise_sentiments({\n",
    "    \"Sentence\":[\"SENTENCE\"] + sentence.split(),\n",
    "    \"Sentiment\":[sid.polarity_scores(sentence)[\"compound\"]] + [sid.polarity_scores(word)[\"compound\"] for word in sentence.split()]\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kacCYDY-Othv"
   },
   "source": [
    "## TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dhAPgCx3dTj2"
   },
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "plSfiNGweYAx"
   },
   "outputs": [],
   "source": [
    "TextBlob(sentence).sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RVYxpyUDdlqB"
   },
   "outputs": [],
   "source": [
    "visualise_sentiments({\n",
    "      \"Sentence\":[\"SENTENCE\"] + sentence.split(),\n",
    "      \"Sentiment\":[TextBlob(sentence).polarity] + [TextBlob(word).polarity for word in sentence.split()],\n",
    "      \"Subjectivity\":[TextBlob(sentence).subjectivity] + [TextBlob(word).subjectivity for word in sentence.split()],\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qjIbmONpOLCi"
   },
   "source": [
    "## Flair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-PmZosdXhI5q"
   },
   "outputs": [],
   "source": [
    "!pip3 install flair\n",
    "import flair\n",
    "flair_sentiment = flair.models.TextClassifier.load('en-sentiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a7vcQnmhipCB"
   },
   "outputs": [],
   "source": [
    "s = flair.data.Sentence(sentence)\n",
    "flair_sentiment.predict(s)\n",
    "total_sentiment = s.labels\n",
    "total_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ND29Oz1akmCO"
   },
   "outputs": [],
   "source": [
    "tokens = [token.text for token in s.tokens]\n",
    "ss = [flair.data.Sentence(s) for s in tokens]\n",
    "[flair_sentiment.predict(s) for s in ss]\n",
    "sentiments = [s.labels[0].score * (-1,1)[str(s.labels[0]).split()[0].startswith(\"POS\")] for s in ss]\n",
    "\n",
    "visualise_sentiments({\n",
    "      \"Sentence\":[\"SENTENCE\"] + tokens,\n",
    "      \"Sentiment\":[total_sentiment[0].score *(-1,1)[str(total_sentiment[0]).split()[0].startswith(\"POS\")]] + sentiments,\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FDRXa8igOVC3"
   },
   "source": [
    "## DeepMoji (Emotions via Emojis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZjGnyAcFsuD3"
   },
   "outputs": [],
   "source": [
    "!pip3 install torch==1.0.1 -f https://download.pytorch.org/whl/cpu/stable \n",
    "!git clone https://github.com/huggingface/torchMoji\n",
    "import os\n",
    "os.chdir('torchMoji')\n",
    "!pip3 install -e ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yfBLwAM0vjL4"
   },
   "source": [
    "type \"yes\" when prompted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FhbEFFbo3EgG"
   },
   "outputs": [],
   "source": [
    "!python3 scripts/download_weights.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hfyjDnld-WIP"
   },
   "outputs": [],
   "source": [
    "!python3 examples/text_emojize.py --text f\" {sentence} \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "peYMP00W_6nk"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import emoji, json\n",
    "from torchmoji.global_variables import PRETRAINED_PATH, VOCAB_PATH\n",
    "from torchmoji.sentence_tokenizer import SentenceTokenizer\n",
    "from torchmoji.model_def import torchmoji_emojis\n",
    "  \n",
    "EMOJIS = \":joy: :unamused: :weary: :sob: :heart_eyes: :pensive: :ok_hand: :blush: :heart: :smirk: :grin: :notes: :flushed: :100: :sleeping: :relieved: :relaxed: :raised_hands: :two_hearts: :expressionless: :sweat_smile: :pray: :confused: :kissing_heart: :heartbeat: :neutral_face: :information_desk_person: :disappointed: :see_no_evil: :tired_face: :v: :sunglasses: :rage: :thumbsup: :cry: :sleepy: :yum: :triumph: :hand: :mask: :clap: :eyes: :gun: :persevere: :smiling_imp: :sweat: :broken_heart: :yellow_heart: :musical_note: :speak_no_evil: :wink: :skull: :confounded: :smile: :stuck_out_tongue_winking_eye: :angry: :no_good: :muscle: :facepunch: :purple_heart: :sparkling_heart: :blue_heart: :grimacing: :sparkles:\".split(' ')\n",
    "model = torchmoji_emojis(PRETRAINED_PATH)\n",
    "with open(VOCAB_PATH, 'r') as f:\n",
    "  vocabulary = json.load(f)\n",
    "st = SentenceTokenizer(vocabulary, 30)\n",
    "\n",
    "def deepmojify(sentence,top_n =5):\n",
    "  def top_elements(array, k):\n",
    "    ind = np.argpartition(array, -k)[-k:]\n",
    "    return ind[np.argsort(array[ind])][::-1]\n",
    "\n",
    "  tokenized, _, _ = st.tokenize_sentences([sentence])\n",
    "  prob = model(tokenized)[0]\n",
    "  emoji_ids = top_elements(prob, top_n)\n",
    "  emojis = map(lambda x: EMOJIS[x], emoji_ids)\n",
    "  return emoji.emojize(f\"{sentence} {' '.join(emojis)}\", use_aliases=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MkRF-2LzCMxI"
   },
   "outputs": [],
   "source": [
    "deepmojify(sentence, top_n = 3)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Sentiment_Analysis.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
